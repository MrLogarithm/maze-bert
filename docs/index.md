---
layout: default
---

# A-maze 

A-maze is an incremental sentence processing method; it's a variant of the Maze task that uses automatically generated distractors. 

On other pages of this site, you can learn [more about the Maze task](intro.md), learn [how to set-up](install.md) and [start using A-maze](usage_basic.md) in your own research, and learn about [running Maze experiments online](ibex.md). 

This is still a work in progress, so if you run into bugs or issues, feel free to raise issues on github or email me. 
 
### Citing A-maze

If you use A-maze in your work, please cite both the A-maze and the papers about whatever model(s) you used.

 - A-maze paper: V. Boyce, R. Futrell, R. P. Levy. 2020. Maze Made Easy: Better and easier measurement of incremental processing difficulty. Journal of Memory and Language.
 - Gulordava model (default model): K. Gulordava, P. Bojanowski, E. Grave, T. Linzen, M. Baroni. 2018. Colorless green recurrent networks dream hierarchically. Proceedings of NAACL.
 - French model: A. An, P. Qian, E. Wilcox, R. P. Levy. 2019. Representation of Constituents in Neural Language Models: Coordination Phrase as a Case Study. EMNLP 2019. 
 
### Projects using A-maze
(This is currently a very short list because I'm not aware of much work using A-maze. If you send me links to pre-prints/posters/other open access work using A-maze, I'll add it here.)

- [Maze Made Easy: Better and easier measurement of incremental processing difficulty](https://psyarxiv.com/b7nqd/)
- ["Ambiguous" isn't "underspecified": Evidence from the Maze task](https://osf.io/zb236/) and [A-maze by any other name](https://osf.io/u8t2d/)
